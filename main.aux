\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\babel@aux{french}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Reproducing Kernel Hilbert space (RKHS) et leurs applications}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Cadre théorique}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Applications des RKHS en machine learning}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Representer theorem}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Exemple 1 : Kernel Ridge Regression}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Exemple 2 : Support Vector Machine (SVM)}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.4}Le Kernel Trick}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction : Réseau de neurone simple}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Lois suivant la largeur des couches $m$}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Choix de $\gamma $}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Gradients}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Descente de gradient}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Choix de $\eta $}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Ordres de grandeur des écarts relatifs}{11}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Choix de $\alpha $}{12}{}\protected@file@percent }
\gdef \@abspage@last{13}
