\relax 
\bbl@cs{beforestart}
\catcode `:\active 
\catcode `;\active 
\catcode `!\active 
\catcode `?\active 
\babel@aux{french}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Reproducing Kernel Hilbert space (RKHS) et leurs applications}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Cadre théorique}{3}\protected@file@percent }
\newlabel{prop:reprotokernel}{{3}{4}}
\newlabel{th:existunicity}{{4}{4}}
\newlabel{th:link2visions}{{2}{4}}
\newlabel{th:mooaron}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Applications des RKHS en machine learning}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Representer theorem}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Exemple 1 : Kernel Ridge Regression}{6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Exemple 2 : Support Vector Machine (SVM)}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.4}Le Kernel Trick}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction : Réseau de neurone simple}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Lois suivant la largeur des couches $m$}{8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Gradients}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Descente de gradient}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Choix de $\eta $}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Ordres de grandeur des écarts relatifs}{10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Choix de $\alpha $}{11}\protected@file@percent }
